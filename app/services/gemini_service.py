# app/services/gemini_service.py
import google.generativeai as genai
from app.core.config import settings
from typing import Dict, List
import json
import re

class GeminiService:
    def __init__(self):
        try:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            
            # --- ¬°CONFIGURACI√ìN FINAL! ---
            # Leer√° 'gemini-flash-latest' desde tu config.py
            self.model_text = genai.GenerativeModel(settings.GEMINI_MODEL)
            self.model_json = genai.GenerativeModel(
                settings.GEMINI_MODEL,
                generation_config={"response_mime_type": "application/json"}
            )
            
            self.conversation_history: Dict[str, List] = {}
            print(f"‚úÖ Servicio de Gemini inicializado con el modelo: {settings.GEMINI_MODEL}")
        except Exception as e:
            print(f"‚ùå Error al configurar Gemini: {e}")
            raise
    
    async def generate_explanation(
        self,
        question: str,
        user_answer: str,
        correct_answer: str,
        subject: str,
        user_level: str
    ) -> str:
        """Genera explicaci√≥n personalizada con Gemini (modelo de texto)"""
        try:
            prompt = f"""Act√∫a como un tutor experto en {subject} para estudiantes preuniversarios peruanos de nivel {user_level}.

Pregunta: {question}
Respuesta del estudiante: {user_answer}
Respuesta correcta: {correct_answer}

Proporciona una explicaci√≥n que incluya:
1. Por qu√© la respuesta correcta es as√≠ (explicaci√≥n clara y concisa)
2. El error conceptual del estudiante (si lo hay)
3. Un consejo espec√≠fico para mejorar
4. Un ejemplo similar corto

S√© emp√°tico, motivador y did√°ctico. Usa emojis ocasionalmente. M√°ximo 200 palabras."""

            response = await self.model_text.generate_content_async(prompt)
            return response.text
        except Exception as e:
            print(f"Error generando explicaci√≥n: {e}")
            raise
    
    async def generate_adaptive_question(
        self,
        subject: str,
        user_level: str,
        weak_topics: List[str],
        recent_performance: Dict
    ) -> Dict:
        """Genera pregunta adaptativa basada en rendimiento (modelo JSON)"""
        try:
            total = recent_performance.get('total', 1)
            correct = recent_performance.get('correct', 0)
            accuracy = (correct / total * 100) if total > 0 else 50
            
            difficulty = 'medio'
            if accuracy > 80:
                difficulty = 'dif√≠cil'
            elif accuracy < 50:
                difficulty = 'f√°cil'
            
            topics_text = f"Enf√≥cate en estos temas d√©biles: {', '.join(weak_topics)}" if weak_topics else "Tema general"
            
            prompt = f"""Genera UNA pregunta de {subject} para examen de admisi√≥n universitaria peruana.

Nivel del estudiante: {user_level}
Rendimiento reciente: {accuracy:.0f}% de aciertos
{topics_text}
Dificultad requerida: {difficulty}

Responde √öNICAMENTE con este JSON:
{{
  "question": "texto de la pregunta",
  "options": ["opci√≥n A", "opci√≥n B", "opci√≥n C", "opci√≥n D"],
  "correct": 0,
  "explanation": "explicaci√≥n detallada de por qu√© la respuesta es correcta",
  "difficulty": "{difficulty}",
  "topic": "tema espec√≠fico"
}}"""

            # Usamos el modelo JSON
            response = await self.model_json.generate_content_async(prompt)
            # No necesitamos limpiar, Gemini lo entrega en JSON
            return json.loads(response.text)
            
        except Exception as e:
            print(f"Error generando pregunta: {e}")
            raise
    
    async def chat_with_tutor(
        self,
        user_id: str,
        message: str,
        context: Dict
    ) -> str:
        """Chat conversacional con el tutor IA (modelo de texto)"""
        try:
            # Obtener o crear historial
            if user_id not in self.conversation_history:
                self.conversation_history[user_id] = []
            
            history = self.conversation_history[user_id]
            
            # Contexto del sistema
            system_context = f"""Eres un tutor virtual experto y motivador en preparaci√≥n preuniversitaria peruana.

Informaci√≥n del estudiante:
- Nombre: {context.get('userName', 'Estudiante')}
- Nivel: {context.get('userLevel', 'principiante')}
- Materias d√©biles: {', '.join(context.get('weakSubjects', [])) or 'no identificadas'}
- Precisi√≥n general: {context.get('accuracy', 0):.1f}%

Tu rol:
- Motivar y guiar al estudiante con entusiasmo
- Responder dudas acad√©micas de forma clara
- Sugerir estrategias de estudio efectivas
- Ser emp√°tico, paciente y cercano
- Usar emojis para hacer la conversaci√≥n amigable
- Adaptar tu lenguaje al nivel del estudiante

IMPORTANTE: Nunca des respuestas directas a ejercicios sin explicar el proceso de razonamiento."""

            # Crear chat con historial
            if len(history) == 0:
                history.append({ "role": "user", "parts": [system_context] })
                history.append({ "role": "model", "parts": ["Entendido. Estoy listo para ayudar al estudiante con entusiasmo y dedicaci√≥n. üìö‚ú®"] })
            
            chat = self.model_text.start_chat(history=history)
            response = await chat.send_message_async(message)
            
            # Actualizar historial (mantener √∫ltimos 20 mensajes)
            history.append({ "role": "user", "parts": [message] })
            history.append({ "role": "model", "parts": [response.text] })
            
            if len(history) > 22:  # 20 mensajes + 2 del sistema
                history = history[:2] + history[-20:]
            
            self.conversation_history[user_id] = history
            
            return response.text
        except Exception as e:
            print(f"Error en chat: {e}")
            raise
    
    async def analyze_study_pattern(
        self,
        user_id: str,
        session_data: Dict
    ) -> str:
        """Analiza el patr√≥n de estudio del estudiante (modelo de texto)"""
        try:
            subject_scores_text = "\n".join([
                f"- {subject}: {score}%"
                for subject, score in session_data.get('subjectScores', {}).items()
            ])
            
            prompt = f"""Analiza el patr√≥n de estudio de este estudiante preuniversitario peruano:

üìä DATOS DEL ESTUDIANTE:
- Sesiones completadas: {session_data.get('sessionsCount', 0)}
- Tiempo total de estudio: {session_data.get('totalMinutes', 0)} minutos
- Racha actual: {session_data.get('streak', 0)} d√≠as consecutivos
- Horarios preferidos: {', '.join(session_data.get('preferredTimes', ['no determinado']))}

üìà RENDIMIENTO POR MATERIA:
{subject_scores_text}

PROPORCIONA (m√°ximo 300 palabras):
1. üéØ An√°lisis del patr√≥n de estudio (fortalezas y debilidad)
2. ‚≠ê 3 fortalezas principales identificadas
3. üîß 3 √°reas de mejora espec√≠ficas
4. üìã Plan de acci√≥n concreto (3 pasos accionables)
5. üéì Predicci√≥n de puntaje en examen real (escala vigesimal 0-20)

S√© motivador, espec√≠fico y realista. Usa emojis. Enf√≥cate en el contexto peruano."""

            response = await self.model_text.generate_content_async(prompt)
            return response.text
        except Exception as e:
            print(f"Error analizando progreso: {e}")
            raise
    
    async def generate_study_plan(
        self,
        user_profile: Dict,
        target_date: str,
        target_score: int
    ) -> Dict:
        """Genera plan de estudio personalizado (modelo JSON)"""
        try:
            from datetime import datetime
            
            try:
                target = datetime.fromisoformat(target_date.replace('Z', '+00:00'))
                days_until_exam = (target - datetime.now()).days
            except ValueError:
                # Si la fecha es inv√°lida, poner un default
                target = datetime.now()
                days_until_exam = 30 # Default

            if days_until_exam <= 0:
                days_until_exam = 30  # Default si la fecha ya pas√≥
            
            subject_scores_text = "\n".join([
                f"- {subject}: {score}%"
                for subject, score in user_profile.get('subjectScores', {}).items()
            ])
            
            prompt = f"""Crea un plan de estudio personalizado para examen de admisi√≥n universitaria peruana:

üë§ PERFIL DEL ESTUDIANTE:
- Nivel actual: {user_profile.get('level', 'principiante')}
- Puntaje actual: {user_profile.get('currentScore', 0):.1f}%
- Puntaje objetivo: {target_score}%
- D√≠as disponibles: {days_until_exam}

üìä RENDIMIENTO POR MATERIA:
{subject_scores_text}

Genera un plan SEMANAL detallado en formato JSON:
{{
  "summary": "resumen ejecutivo del plan en 2-3 l√≠neas",
  "weeklyGoals": ["objetivo semana 1", "objetivo semana 2", "objetivo semana 3", "objetivo semana 4"],
  "dailySchedule": [
    {{
      "day": "Lunes",
      "subjects": ["Matem√°tica", "Razonamiento Verbal"],
      "topics": ["√Ålgebra b√°sica", "Analog√≠as"],
      "estimatedTime": 90,
      "goals": ["Resolver 20 problemas de √°lgebra"]
    }},
    {{
      "day": "Martes",
      "subjects": ["Razonamiento Matem√°tico"],
      "topics": ["Series num√©ricas"],
      "estimatedTime": 60,
      "goals": ["Dominar 5 tipos de series"]
    }}
  ],
  "milestones": [
    {{
      "week": 1,
      "goal": "Reforzar bases en matem√°tica",
      "expectedScore": 65
    }},
    {{
      "week": 2,
      "goal": "Mejorar razonamiento verbal",
      "expectedScore": 70
    }}
  ],
  "tips": ["Consejo pr√°ctico 1", "Consejo pr√°ctico 2", "Consejo pr√°ctico 3"]
}}"""

            # Usamos el modelo JSON
            response = await self.model_json.generate_content_async(prompt)
            return json.loads(response.text)
            
        except Exception as e:
            print(f"Error generando plan: {e}")
            raise
    
    async def generate_motivational_feedback(
        self,
        performance: Dict,
        context: Dict
    ) -> str:
        """Genera feedback motivacional personalizado (modelo de texto)"""
        try:
            prompt = f"""Genera un mensaje motivacional personalizado para un estudiante preuniversitario peruano:

üìä RENDIMIENTO DE HOY:
- Preguntas respondidas: {performance.get('questionsAnswered', 0)}
- Respuestas correctas: {performance.get('correctAnswers', 0)}
- Tiempo estudiado: {performance.get('timeSpent', 0)} minutos
- Racha: {performance.get('streak', 0)} d√≠as consecutivos

üìà CONTEXTO:
- Tendencia: {performance.get('trending', 'estable')}
- Estado de √°nimo: {context.get('mood', 'neutral')}
- Objetivo: {context.get('goal', 'ingresar a la universidad')}

Genera un mensaje de m√°ximo 120 palabras que:
1. üéâ Reconozca el esfuerzo espec√≠fico de hoy
2. ‚≠ê Destaque UN logro concreto
3. üí° Proporcione UN consejo accionable para ma√±ana
4. üöÄ Termine con motivaci√≥n energ√©tica

Usa un tono cercano, amigable y motivador. Incluye emojis. Enf√≥cate en el contexto peruano."""

            response = await self.model_text.generate_content_async(prompt)
            return response.text
        except Exception as e:
            print(f"Error generando feedback: {e}")
            raise
    
    def clear_conversation_history(self, user_id: str):
        """Limpia el historial de conversaci√≥n"""
        if user_id in self.conversation_history:
            del self.conversation_history[user_id]

# Instancia global
gemini_service = GeminiService()